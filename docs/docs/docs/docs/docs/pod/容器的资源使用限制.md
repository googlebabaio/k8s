
# 什么是pod的资源请求与资源限制？


当创建一个Pod的时候，需要为运行在Pod中的容器请求CPU和RAM资源，还可以设置CPU和RAM资源的限制。

- 请求CPU和RAM资源，在配置文件里面使用`resources:rquests`字段
- 设置CPU和RAM限制，在配置文件里面使用`resources:limits`字段

## 单位说明
CPU资源以cpus为单位。允许小数值,可以用后缀m来表示mili。例如100m cpu等同于100 milicpu，意思是0.1cpu。
RAM资源以bytes为单位。可以将RAM表示为纯整数或具有这些后缀之一的定点整数： E, P, T, G, M, K, Ei, Pi, Ti, Gi, Mi, Ki。

- 申请资源：表示容器使用的最小CPU/内存的值，即工作负载能够运行起来工作所需要的最小资源 （申请资源过多，会占用集群过多资源，导致资源不足，工作负载部署不起来）
- 限制资源：表示容器使用的最大CPU/内存的值，即工作负载处理最大业务流量所需要的最大资源（申请资源过少，会导致工作负载运行中因为资源不足而异常）

## 使用说明
- 如果节点上具有足够的CPU和RAM资源可用于所有容器要求的CPU和RAM总和，k8s将把Pod调度在上面。
- 同样当容器运行在节点上时，k8s 不允许容器消耗的CPU和RAM资源超出指定的容器的限制。
- 如果容器超出RAM限制，pod将结束。如果CPU超出限制，它将成为CPU节流的候选者。

例子：
Pod请求250mili cpu和64 mebibytes RAM，同时设置上线为1cpu和128 mebibytes RAM
```
apiVersion: v1
kind: Pod
metadata:
  name: cpu-ram-demo
spec:
  containers:
  - name: cpu-ram-demo-container
    image: gcr.io/google-samples/node-hello:1.0
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "1"
```

# 是否必须设置工作负载的值？

必须设置。

如果不设置，会带来如下影响：
1. 工作负载的监控数据不准确；
2. 会因为未配置资源限制的工作负载（内存泄漏等）占用太多的资源，而导致其他工作负载使用不到资源或者节点资源耗尽而异常
